{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import torch\n",
    "import scipy\n",
    "import keras\n",
    "import scipy.spatial.distance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras import Regularizer \n",
    "from keras import backend\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11ba05c70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(18229)\n",
    "torch.manual_seed(94892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mazeGeneratorI():\n",
    "    '''\n",
    "    Objects of the mazeGeneratorI class can create numpy and tf datasets of the first choice of the maze task.\n",
    "    Task structure:\n",
    "        Goal presentation, followed by delay period, followed by choice options.\n",
    "    Response:\n",
    "        One response required from agent at end of episode. Direction (Left, Up, Right, Down) of first step.\n",
    "    Encoding:\n",
    "        Both observations and labels are OneHot encoded.\n",
    "    Usage:\n",
    "        The two only function a user should need to access are \"construct_numpy_data\" and \"construct_tf_data\"\n",
    "    Options:\n",
    "        Both data construction methods have an option to shuffle the labels of data.\n",
    "        The numpy data construction method allows to also return the maze identifiers.\n",
    "    '''\n",
    "    def __init__(self, goal_presentation_steps, delay_steps, choices_presentation_steps):\n",
    "        self.version = 'v1.2.0'\n",
    "        \n",
    "        # Import variables defining episode\n",
    "        self.goal_presentation_steps = goal_presentation_steps\n",
    "        self.delay_steps = delay_steps\n",
    "        self.choices_presentation_steps = choices_presentation_steps\n",
    "\n",
    "        # Construct mazes dataframe\n",
    "        ## Add encoded versions of the goal / choices presentations and the next step response\n",
    "        self.mazesdf = self.import_maze_dic()\n",
    "        self.mazesdf['Goal_Presentation'] = self.mazesdf['goal'].map({\n",
    "            7:np.concatenate((np.array([1,0,0,0]),np.repeat(0,4))),\n",
    "            9:np.concatenate((np.array([0,1,0,0]),np.repeat(0,4))),\n",
    "            17:np.concatenate((np.array([0,0,1,0]),np.repeat(0,4))),\n",
    "            19:np.concatenate((np.array([0,0,0,1]),np.repeat(0,4)))})\n",
    "        self.mazesdf['Choices_Presentation']=self.mazesdf['ChoicesCategory'].map(lambda x: self.encode_choices(x=x))\n",
    "        self.mazesdf['Step_Encoded']=self.mazesdf['NextFPmap'].map(lambda x: self.encode_next_step(x=x))\n",
    "\n",
    "    def construct_numpy_data(self, number_of_problems, return_maze_identifiers = False, np_shuffle_data = False):\n",
    "        # Create a new column which hold the vector for each problem\n",
    "        self.mazesdf['Problem_Vec']=self.mazesdf.apply(lambda x: self.create_problem_observation(row= x,goal_presentation_steps= self.goal_presentation_steps,delay_steps= self.delay_steps,choices_presentation_steps= self.choices_presentation_steps), axis=1)\n",
    "        # Set a random order of maze problems for the current session\n",
    "        self.mazes_order = np.random.randint(0,8,number_of_problems)\n",
    "\n",
    "        # Create vectors, holding observations and labels\n",
    "        session_observation =np.array([])\n",
    "        session_labels = np.array([])\n",
    "        for i in self.mazes_order:\n",
    "            session_observation = np.append(session_observation,self.mazesdf.iloc[i]['Problem_Vec'])\n",
    "            session_labels = np.append(session_labels,self.mazesdf.iloc[i]['Step_Encoded'])\n",
    "\n",
    "        # Reshape vectors to fit network observation and response space\n",
    "        session_length = self.goal_presentation_steps + self.delay_steps + self.choices_presentation_steps\n",
    "        session_observation = np.reshape(session_observation, (-1,session_length,8)).astype('float32')\n",
    "        session_labels = np.reshape(session_labels, (-1,4)).astype('float32')\n",
    "\n",
    "        # If np_shuffle_data == 'Labels, the order of labels is shuffled to randomise correct answers\n",
    "        if np_shuffle_data == 'Labels':\n",
    "          shuffle_generator = np.random.default_rng(38446)\n",
    "          shuffle_generator.shuffle(session_labels,axis=0)\n",
    "\n",
    "        # If return_maze_identifiers == 'IDs', return the array with maze IDs alongside the regular returns (observations, labels)\n",
    "        if return_maze_identifiers == 'IDs':\n",
    "          return session_observation, session_labels, self.mazes_order\n",
    "\n",
    "        return session_observation, session_labels\n",
    "\n",
    "    def construct_pytorch_data(self, number_of_problems, batch_size, shuffle_data=False):\n",
    "        # Create dataset as described by the numpy dataset function\n",
    "        npds, np_labels = self.construct_numpy_data(number_of_problems=number_of_problems, np_shuffle_data=shuffle_data)\n",
    "        \n",
    "        # Convert NumPy arrays to PyTorch tensors\n",
    "        tensor_ds = torch.tensor(npds, dtype=torch.float32)\n",
    "        tensor_labels = torch.tensor(np_labels, dtype=torch.float32)\n",
    "\n",
    "        # Create a TensorDataset and DataLoader for batching and shuffling\n",
    "        dataset = TensorDataset(tensor_ds, tensor_labels)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle_data)\n",
    "        \n",
    "        return dataloader\n",
    "\n",
    "    def reset_construction_params(self, goal_presentation_steps, delay_steps, choices_presentation_steps):\n",
    "        self.goal_presentation_steps = goal_presentation_steps\n",
    "        self.delay_steps = delay_steps\n",
    "        self.choices_presentation_steps = choices_presentation_steps\n",
    "\n",
    "    def import_maze_dic(self, mazeDic=None):\n",
    "        if mazeDic is None:\n",
    "            # Set up dataframe with first choices of maze task\n",
    "            ## The dictionary was generated using MazeMetadata.py (v1.0.0) and the following call:\n",
    "            ### mazes.loc[(mazes['Nsteps']==2)&(mazes['ChoiceNo']=='ChoiceI')][['goal','ChoicesCategory','NextFPmap']].reset_index(drop=True).to_dict()\n",
    "            self.mazesDic = {'goal': {0: 9, 1: 9, 2: 19, 3: 17, 4: 17, 5: 7, 6: 19, 7: 7},\n",
    "            'ChoicesCategory': {0: 'ul',\n",
    "            1: 'rd',\n",
    "            2: 'ld',\n",
    "            3: 'rd',\n",
    "            4: 'ul',\n",
    "            5: 'ur',\n",
    "            6: 'lr',\n",
    "            7: 'lr'},\n",
    "            'NextFPmap': {0: 'u', 1: 'r', 2: 'd', 3: 'd', 4: 'l', 5: 'u', 6: 'r', 7: 'l'}}\n",
    "        else:\n",
    "            self.mazesDic = mazeDic\n",
    "        \n",
    "        # Create and return dataframe\n",
    "        return pd.DataFrame(self.mazesDic)\n",
    "\n",
    "    def encode_choices(self, x):\n",
    "        # Helper function to create the observation vector for choice periods\n",
    "        choices_sec = np.repeat(0,4)\n",
    "        choicesEncoding = pd.Series(list(x))\n",
    "        choicesEncoding = choicesEncoding.map({'l':1,'u':2,'r':3,'d':4})\n",
    "        for encodedChoice in choicesEncoding:\n",
    "            choices_sec[encodedChoice-1]=1\n",
    "        return np.concatenate((np.repeat(0,4),choices_sec))\n",
    "\n",
    "    def encode_next_step(self, x):\n",
    "        # Helper function to change the response / action to a OneHot encoded vector\n",
    "        step_sec = np.repeat(0,4)\n",
    "        stepEncoding = pd.Series(list(x))\n",
    "        stepEncoding = stepEncoding.map({'l':1,'u':2,'r':3,'d':4})\n",
    "        for encodedStep in stepEncoding:\n",
    "            step_sec[encodedStep-1]=1\n",
    "        return step_sec\n",
    "\n",
    "    def create_problem_observation(self, row, goal_presentation_steps, delay_steps, choices_presentation_steps):\n",
    "        # Helper function to create one vector describing the entire outline of one maze problem (Goal presentation, Delay Period, and Choices Presentation)\n",
    "        goal_vec = np.tile(row['Goal_Presentation'], goal_presentation_steps)\n",
    "        delay_vec = np.tile(np.repeat(0,8), delay_steps)\n",
    "        choices_vec = np.tile(row['Choices_Presentation'], choices_presentation_steps)\n",
    "        problem_vec = np.concatenate((goal_vec,delay_vec,choices_vec))\n",
    "        return problem_vec\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Maze DataSet Generator',\n",
    "            f'Goal Presentation Steps: {self.goal_presentation_steps}',\n",
    "            f'Delay Steps: {self.delay_steps}',\n",
    "            f'Choices Presentation Steps: {self.choices_presentation_steps}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x175f3e7d0>\n"
     ]
    }
   ],
   "source": [
    "# This constructor might run for around a minute to generate the dataset\n",
    "gen = mazeGeneratorI(goal_presentation_steps=20,delay_steps=10,choices_presentation_steps=20)\n",
    "torchdf = gen.construct_pytorch_data(number_of_problems=5120, batch_size=128)\n",
    "torchdf_test = gen.construct_pytorch_data(number_of_problems=2560, batch_size=128)\n",
    "torchdf_val = gen.construct_pytorch_data(number_of_problems=2560, batch_size=128)\n",
    "print(torchdf)\n",
    "\n",
    "example_data = next(iter(torchdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SE1(Regularizer):\n",
    "  \"\"\"A regulariser for sptially embedded RNNs.\n",
    "  Applies L1 regularisation to recurrent kernel of\n",
    "  RNN which is weighted by the distance of units\n",
    "  in predefined 3D space.\n",
    "  Calculation:\n",
    "      se1 * sum[distance_matrix o recurrent_kernel]\n",
    "  Attributes:\n",
    "      se1: Float; Weighting of SE1 regularisation term.\n",
    "      distance_tensor: TF tensor / matrix with cost per\n",
    "      connection in weight matrix of network.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, se1=0.01, neuron_num = 100, network_structure = (5,5,4), coordinates_list = None, distance_power = 1, distance_metric = 'euclidean'):  \n",
    "    self.version = 'v1.1.0'\n",
    "    self.distance_power = distance_power\n",
    "    \n",
    "    # Set SE1 regularisation strength to default of 0.01 if no value given\n",
    "    se1 = 0.01 if se1 is None else se1\n",
    "    self._check_penalty_number(se1)\n",
    "    self.se1 = se1\n",
    "\n",
    "    # Set up tensor with distance matrix\n",
    "    ## Set up neurons per dimension\n",
    "    nx = np.arange(network_structure[0])\n",
    "    ny = np.arange(network_structure[1])\n",
    "    nz = np.arange(network_structure[2])\n",
    "\n",
    "    ## Set up coordinate grid\n",
    "    [x,y,z] = np.meshgrid(nx,ny,nz)\n",
    "    self.coordinates = [x.ravel(),y.ravel(),z.ravel()]\n",
    "\n",
    "    ## Override coordinate grid if one if provided in init\n",
    "    if coordinates_list is not None:\n",
    "      self.coordinates = coordinates_list\n",
    "\n",
    "    ## Check neuron number / number of coordinates\n",
    "    if (len(self.coordinates[0])==neuron_num)&(len(self.coordinates[1])==neuron_num)&(len(self.coordinates[2])==neuron_num):\n",
    "      pass\n",
    "    else:\n",
    "      raise ValueError('Network / coordinate structure does not match the number of neurons.')\n",
    "\n",
    "    ## Calculate the euclidean distance matrix\n",
    "    euclidean_vector = scipy.spatial.distance.pdist(np.transpose(self.coordinates), metric=distance_metric)\n",
    "    euclidean = scipy.spatial.distance.squareform(euclidean_vector**self.distance_power)\n",
    "    self.distance_matrix = euclidean.astype('float32')\n",
    "    self.spatial_cost_matrix = self.distance_matrix\n",
    "\n",
    "    ## Add minimal cost for recurrent self connection (on diagonal)\n",
    "    #diag_dist = np.diag(np.repeat(0.1,100)).astype('float32')\n",
    "    #self.distance_matrix = self.distance_matrix + diag_dist\n",
    "\n",
    "    ## Create tensor from distance matrix\n",
    "    self.distance_tensor =  torch.from_numpy(self.distance_matrix)\n",
    "\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # Add calculation of loss here.\n",
    "    # L1 for reference: self.l1 * math_ops.reduce_sum(math_ops.abs(x))\n",
    "    abs_weight_matrix = torch.abs(x)\n",
    "\n",
    "    #se1_loss = self.se1 * tf.math.multiply(abs_weight_matrix, self.distance_tensor)\n",
    "    #se1_loss = tf.math.reduce_sum(abs_weight_matrix)\n",
    "    se1_loss = self.se1 * torch.sum(torch.multiply(abs_weight_matrix, self.distance_tensor))\n",
    "    \n",
    "    return se1_loss\n",
    "\n",
    "  def _check_penalty_number(self, x):\n",
    "    \"\"\"check penalty number availability, raise ValueError if failed.\"\"\"\n",
    "    if not isinstance(x, (float, int)):\n",
    "      raise ValueError(('Value: {} is not a valid regularization penalty number, '\n",
    "                        'expected an int or float value').format(x))\n",
    "\n",
    "  def visualise_distance_matrix(self):\n",
    "    plt.imshow(self.distance_matrix)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "  def visualise_neuron_structure(self):\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter(self.coordinates[0],self.coordinates[1],self.coordinates[2],c='b',marker='.')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    plt.show()\n",
    "\n",
    "  def get_config(self):\n",
    "    return {'se1': float(self.se1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE1_sWc(SE1):\n",
    "    '''\n",
    "    Version of SE1 regulariser which combines the spatial and communicability parts in loss function.\n",
    "    Additional comms_factor scales the communicability matrix.\n",
    "    The communicability term used here is unbiased weighted communicability:\n",
    "    Crofts, J. J., & Higham, D. J. (2009). A weighted communicability measure applied to complex brain networks. Journal of the Royal Society Interface, 6(33), 411-414.\n",
    "    '''\n",
    "    def __init__(self, se1=0.01, comms_factor = 1, neuron_num = 100, network_structure = (5,5,4), coordinates_list = None, distance_power = 1, distance_metric = 'euclidean'):\n",
    "      SE1.__init__(self, se1, neuron_num , network_structure , coordinates_list, distance_power , distance_metric)\n",
    "      self.comms_factor = comms_factor\n",
    "\n",
    "    def __call__(self, x):\n",
    "      # Take absolute of weights\n",
    "      abs_weight_matrix = torch.abs(x)\n",
    "\n",
    "      # Calulcate weighted communicability (see reference in docstring)\n",
    "      stepI = torch.sum(abs_weight_matrix, axis=1)\n",
    "      stepII = torch.pow(stepI, -0.5)\n",
    "      stepIII = torch.diag(stepII)\n",
    "      stepIV = torch.matrix_exp(stepIII@abs_weight_matrix@stepIII)\n",
    "      comms_matrix = stepIV.clone()  # Create a copy to avoid modifying the original tensor\n",
    "      comms_matrix.diagonal(dim1=-2, dim2=-1).zero_()  # Set diagonal to zeros in-place\n",
    "\n",
    "      # Multiply absolute weights with communicability weights\n",
    "      comms_matrix = comms_matrix**self.comms_factor\n",
    "      comms_weight_matrix = torch.multiply(abs_weight_matrix, comms_matrix)\n",
    "\n",
    "      # Multiply comms weights matrix with distance tensor, scale the mean, and return as loss\n",
    "      se1_loss = self.se1 * torch.sum(torch.multiply(comms_weight_matrix , self.distance_tensor))\n",
    "      \n",
    "      return se1_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RNNWeightMatrixHistoryI(keras.callbacks.Callback):\n",
    "    '''\n",
    "    Saves the RNN_Weight_Matrix to the training history before\n",
    "    the start of training and after finishing each epoch.\n",
    "\n",
    "    The network model needs to be build manually before calling fit() method\n",
    "    for this callback to work.\n",
    "    '''\n",
    "    def __init__(self, RNN_layer_number = 0):\n",
    "        super(RNNWeightMatrixHistoryI, self).__init__()\n",
    "        self.RNN_layer_number = RNN_layer_number\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        # Create key for RNN_Weight_Matrix in history\n",
    "        self.model.history.history['RNN_Weight_Matrix'] = []\n",
    "        #print(\"Created key for RNN_Weight_Matrix in history.\")\n",
    "\n",
    "        # Save matrix before start of training\n",
    "        self.model.history.history['RNN_Weight_Matrix'].append(self.model.layers[self.RNN_layer_number].get_weights()[1])\n",
    "        #print(\"Saved RNN_Weight_Matrix to history.\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Save RNN_Weight_Matrix to history\n",
    "        self.model.history.history['RNN_Weight_Matrix'].append(self.model.layers[self.RNN_layer_number].get_weights()[1])\n",
    "        #print(\"Saved RNN_Weight_Matrix to history.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regu_strength = 0.3\n",
    "\n",
    "backend.clear_session()\n",
    "regu = SE1_sWc(se1=regu_strength)\n",
    "coord = regu.coordinates\n",
    "cost = regu.spatial_cost_matrix\n",
    "\n",
    "## Assemble network\n",
    "tf_model = keras.models.Sequential([\n",
    "    keras.layers.GaussianNoise(stddev=0.05),\n",
    "    keras.layers.SimpleRNN(100, activation='relu',recurrent_initializer='orthogonal', return_sequences=False, recurrent_regularizer= regu),\n",
    "    keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "tf_model.build(input_shape=example_data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling SimpleRNNCell.call().\n\n\u001b[1mThe operator 'aten::linalg_qr.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\u001b[0m\n\nArguments received by SimpleRNNCell.call():\n  • sequence=torch.Tensor(shape=torch.Size([128, 8]), dtype=float32)\n  • states=('torch.Tensor(shape=torch.Size([128, 100]), dtype=float32)',)\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_ENABLE_MPS_FALLBACK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m*\u001b[39mexample_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtf_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling SimpleRNNCell.call().\n\n\u001b[1mThe operator 'aten::linalg_qr.out' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.\u001b[0m\n\nArguments received by SimpleRNNCell.call():\n  • sequence=torch.Tensor(shape=torch.Size([128, 8]), dtype=float32)\n  • states=('torch.Tensor(shape=torch.Size([128, 100]), dtype=float32)',)\n  • training=False"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "dummy_input = np.random.randn(*example_data[0].shape).astype(np.float32)\n",
    "tf_model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Variable sequential/simple_rnn/simple_rnn_cell/kernel is already initialized.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTORCH_ENABLE_MPS_FALLBACK\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorchdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorchdf_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRNNWeightMatrixHistoryI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRNN_layer_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/dynamically-seRNNs-jOYgDnHA/lib/python3.11/site-packages/keras/src/trainers/trainer.py:1091\u001b[0m, in \u001b[0;36mTrainer._symbolic_build\u001b[0;34m(self, iterator, data_batch)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\u001b[38;5;28mself\u001b[39m, x, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1092\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to automatically build the model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease build it yourself before calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit/evaluate/predict. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1095\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA model is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuilt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when its variables have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1096\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeen created and its `self.built` attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis True. Usually, calling the model on a batch \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1098\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof data is the right way to build it.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException encountered:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1101\u001b[0m     )\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_metrics_unbuilt:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;66;03m# Build all metric state with `backend.compute_output_spec`.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m     backend\u001b[38;5;241m.\u001b[39mcompute_output_spec(\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics,\n\u001b[1;32m   1106\u001b[0m         x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1110\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Variable sequential/simple_rnn/simple_rnn_cell/kernel is already initialized.'"
     ]
    }
   ],
   "source": [
    "history = tf_model.fit(torchdf, epochs=10,validation_data=torchdf_test,\n",
    "                       callbacks=RNNWeightMatrixHistoryI(RNN_layer_number=1)\n",
    "                       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Pipenv)",
   "language": "python",
   "name": "dynamically-sernns-joygdnha"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
